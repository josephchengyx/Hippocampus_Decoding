{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from preproc import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which sessions' dataset to use\n",
    "prefix = \"/Volumes/Hippocampus/Data/picasso-misc/\"\n",
    "month_list = [\"201811\", \"201810\", \"201809\", \"201808\", \"201807\"]\n",
    "\n",
    "# Save directory for data files\n",
    "save_dir = \"data/combined\"\n",
    "\n",
    "# Whether to overwrite preexisting files\n",
    "overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of days from list of months\n",
    "day_list = list()\n",
    "for month in month_list:\n",
    "    result = subprocess.run(f'find {prefix} -type d -maxdepth 1 -name \"{month}*\" | cut -f 7 -d \"/\"', stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True, text=True)\n",
    "    day_list.extend(result.stdout.split('\\n'))\n",
    "day_list = list(filter(lambda str: str, day_list))\n",
    "day_list.sort(reverse=True)\n",
    "\n",
    "# Filter out these 4 days\n",
    "blacklist = [\"20180927\", \"20180821\", \"20180816\", \"20180711\"]\n",
    "for day in blacklist:\n",
    "    if day in day_list:\n",
    "        day_list.remove(day)\n",
    "\n",
    "# Create directory to save data files to\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save list of days as a txt file\n",
    "with open(f'{save_dir}/days.txt', 'w') as file:\n",
    "    for day in day_list:\n",
    "        file.write(f'{day}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For processing hint/nav end phase data\n",
    "\n",
    "# Grab periods in the navigation phase when the hint image was looked at\n",
    "# As well as which goal it corresponded to\n",
    "def chunk_into_intervals(timepts: np.array, tbin: float=0.001) -> np.array:\n",
    "    intervals = list()\n",
    "    i, st = 0, None\n",
    "    while i < timepts.shape[0]:\n",
    "        curr = timepts[i]\n",
    "        if st is None:\n",
    "            st = curr\n",
    "        elif curr > prev + 1.1 * tbin:\n",
    "            intervals.append(np.array([st, prev+tbin]))\n",
    "            st = curr\n",
    "        prev = curr\n",
    "        i += 1\n",
    "    if st is not None:\n",
    "        intervals.append(np.array([st, prev+tbin]))\n",
    "    return np.array(intervals)\n",
    "\n",
    "# View bins for all of the posters on the pillar walls\n",
    "poster_viewbins = np.concatenate([np.arange(4533,4536+1), np.arange(4565,4568+1), np.arange(4597,4600+1), np.arange(4685,4688+1), np.arange(4717,4720+1), np.arange(4749,4752+1),\\\n",
    "                                    np.arange(4701,4704+1), np.arange(4733,4736+1), np.arange(4765,4768+1), np.arange(4845,4848+1), np.arange(4877,4480+1), np.arange(4909,4912+1),\\\n",
    "                                        np.arange(4861,4864+1), np.arange(4893,4896+1), np.arange(4925,4928+1), np.arange(4997,5000+1), np.arange(5029,5032+1), np.arange(5061,5064+1)])\n",
    "poster_viewbins = set(poster_viewbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x9/1nq85w8s11l0sv1yqg3364200000h2/T/ipykernel_31877/198587414.py:198: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  spikerates_hints[i,:] = np.sum(trial, axis=0)/np.sum(timebins_cue[i][:,1]-timebins_cue[i][:,0])\n",
      "/var/folders/x9/1nq85w8s11l0sv1yqg3364200000h2/T/ipykernel_31877/198587414.py:198: RuntimeWarning: invalid value encountered in true_divide\n",
      "  spikerates_hints[i,:] = np.sum(trial, axis=0)/np.sum(timebins_cue[i][:,1]-timebins_cue[i][:,0])\n"
     ]
    }
   ],
   "source": [
    "for day_dir in day_list:\n",
    "    if os.path.exists(f'{save_dir}/{day_dir}_data.pkl') and not overwrite:\n",
    "        continue\n",
    "\n",
    "    ### Load in data from files ###\n",
    "\n",
    "    # Get list of cells under the day directory\n",
    "    os.system(f\"sh ~/Documents/neural_decoding/Hippocampus_Decoding/get_cells.sh {day_dir}\")\n",
    "    cell_list = list()\n",
    "    with open(\"cell_list.txt\", \"r\") as file:\n",
    "        for line in file.readlines():\n",
    "            cell_list.append(line.strip())\n",
    "    os.system(\"rm cell_list.txt\")\n",
    "\n",
    "    # Load data from rplparallel.mat object, extract trial markers, time stamps and session start timestamp\n",
    "    rp_file = h5py.File(prefix + day_dir + \"/session01/rplparallel.mat\")\n",
    "    rp = rp_file.get('rp').get('data')\n",
    "    trial_markers = np.array(rp.get('markers'))\n",
    "    trial_timestamps = np.round(np.array(rp.get('timeStamps')), 3)\n",
    "    session_start_time = np.round(np.array(rp.get('session_start_sec'))[0,0], 3)\n",
    "    rp_file.close()\n",
    "\n",
    "    # Load data and extract spike times from all spiketrain.mat objects\n",
    "    spike_times = list()\n",
    "    cell_labels = list()\n",
    "    for cell_dir in cell_list:\n",
    "        try:\n",
    "            spk_file = loadmat(prefix + day_dir + \"/session01/\" + cell_dir + \"/spiketrain.mat\")\n",
    "        except NotImplementedError:\n",
    "            spk_file = h5py.File(prefix + day_dir + \"/session01/\" + cell_dir + \"/spiketrain.mat\")\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        spk = np.array(spk_file.get('timestamps')).flatten() # spike timestamps is loaded in as a column vector\n",
    "        spk /= 1000 # convert spike timestamps from msec to sec\n",
    "        spike_times.append(spk)\n",
    "        if isinstance(spk_file, h5py.File):\n",
    "            spk_file.close()\n",
    "        \n",
    "        cell_name = cell_dir.split('/')\n",
    "        array, channel, cell = cell_name[0][6:], cell_name[1][7:], cell_name[2][5:]\n",
    "        if channel[0] == '0':\n",
    "            channel = channel[1:]\n",
    "        cell_labels.append(f'a{array}/ch{channel}/c{cell}')\n",
    "\n",
    "    # Load data from vmpv.mat object, extract session end timestamp\n",
    "    pv_file = h5py.File(prefix + day_dir + \"/session01/1vmpv.mat\")\n",
    "    pv = pv_file.get('pv').get('data')\n",
    "    session_end_time = np.round(np.array(pv.get('rplmaxtime'))[0,0], 3)\n",
    "    pv_file.close()\n",
    "\n",
    "    # Load data from binData.hdf object, extract view bin data\n",
    "    viewbin_data = np.genfromtxt(prefix + day_dir + \"/session01/1binData.csv\", delimiter=',')\n",
    "    viewbin_data[:,0] /= 1000 # convert eyelink timestamps from msec to sec\n",
    "\n",
    "\n",
    "    ### Data preprocessing ###\n",
    "\n",
    "    # Define important constants\n",
    "    num_cells = len(cell_labels)\n",
    "    num_goals = 6\n",
    "    time_res = 0.001\n",
    "    tbin_size = 0.1\n",
    "\n",
    "    # Get trial outcomes from trial markers\n",
    "    # 0 for unsuccessful trials, 1 for successful trials\n",
    "    trial_outcomes = 4 - trial_markers[2,:] // 10\n",
    "    trial_outcomes = trial_outcomes.astype(int)\n",
    "\n",
    "    # Get poster numbers from trial markers, cue phase time intervals\n",
    "    trial_markers = trial_markers[0,:] % 10\n",
    "    trial_markers = trial_markers.astype(int)\n",
    "    cue_intervals = trial_timestamps[0:2,:].T\n",
    "\n",
    "    # Get durations of each navigation phase\n",
    "    nav_intervals = trial_timestamps[1:,:].T\n",
    "    nav_durations = nav_intervals[:,1] - nav_intervals[:,0]\n",
    "\n",
    "    # Generate time intervals for each trial\n",
    "    trial_intervals = np.empty_like(cue_intervals)\n",
    "    trial_intervals[:,0] = cue_intervals[:,1]\n",
    "    trial_intervals[:-1,1] = cue_intervals[1:,0]\n",
    "    trial_intervals[-1,1] = session_end_time\n",
    "\n",
    "    # Generate time intervals for each inter-trial interval\n",
    "    iti_intervals = np.empty_like(cue_intervals)\n",
    "    iti_intervals[:,0] = nav_intervals[:,1]\n",
    "    iti_intervals[:-1,1] = cue_intervals[1:,0]\n",
    "    iti_intervals[-1,1] = session_end_time\n",
    "\n",
    "    # Further differentiate trial markers into trial trajectories (start poster, end poster)\n",
    "    trial_trajectories = np.zeros((trial_markers.shape[0], 2))\n",
    "    trial_trajectories[:,1] = trial_markers\n",
    "    trial_trajectories[1:,0] = trial_markers[:-1]\n",
    "\n",
    "    # Filter out trials that are too long (> 25 seconds) or have repeated goal from previous trial\n",
    "    good_trials = np.ones(trial_markers.shape, dtype=np.int8)\n",
    "    max_dur = 25  # maximum duration of trials (in seconds) to filter out\n",
    "    prev_goal = 0\n",
    "    for num, dur in enumerate(nav_durations):\n",
    "        curr_goal = trial_markers[num]\n",
    "        if dur > max_dur or curr_goal == prev_goal:\n",
    "            good_trials[num] = 0\n",
    "        prev_goal = curr_goal\n",
    "    trial_filt = np.where(good_trials == 1)\n",
    "\n",
    "    trial_outcomes = trial_outcomes[trial_filt]\n",
    "    trial_markers = trial_markers[trial_filt]\n",
    "    cue_intervals = cue_intervals[trial_filt]\n",
    "    nav_intervals = nav_intervals[trial_filt]\n",
    "    nav_durations = nav_durations[trial_filt]\n",
    "    trial_intervals = trial_intervals[trial_filt]\n",
    "    iti_intervals = iti_intervals[trial_filt]\n",
    "    trial_trajectories = trial_trajectories[trial_filt]\n",
    "\n",
    "\n",
    "    ### Cue phase, 100 ms time bins ###\n",
    "\n",
    "    # Preallocate list of arrays for spike counts per time bin in cue phase\n",
    "    # Then slot spikes into cue phase intervals, using time bin resolution specified by tbin_size\n",
    "    timebins_cue, spikecounts_cue = list(), list()\n",
    "    for trial in cue_intervals:\n",
    "        st_time, ed_time = trial\n",
    "        ed_time = st_time + one_second\n",
    "        timebins_cue_trial = np.hstack([np.arange(st_time, ed_time, tbin_size).reshape(-1,1), np.arange(st_time, ed_time, tbin_size).reshape(-1,1) + tbin_size])\n",
    "        timebins_cue.append(timebins_cue_trial)\n",
    "        spikecounts_cue.append(np.array(spike_counts_per_observation(timebins_cue_trial, spike_times)))\n",
    "\n",
    "    # Convert spike counts to average spike rates across duration of cue phase\n",
    "    spikerates_cue = [trial/tbin_size for trial in spikecounts_cue]\n",
    "\n",
    "    # Filter out trials with nans in cue spike rates\n",
    "    goals_cue = trial_markers.copy()\n",
    "    trajectories_cue = trial_trajectories.copy()\n",
    "\n",
    "    # Package variables for saving\n",
    "    cue_100ms = {'spikerates_cue': spikerates_cue, 'goals_cue': goals_cue, 'trajectories_cue': trajectories_cue}\n",
    "\n",
    "\n",
    "    ### Cue phase, mean over cue image views ###\n",
    "\n",
    "    # Extract periods in cue phase where cue image was not looked at\n",
    "    # Preallocate list of arrays for spike counts per time bin in cue phase\n",
    "    cueimg_filter = list()\n",
    "    timebins_cue = list()\n",
    "    spikecounts_cue = list()\n",
    "    for trial in cue_intervals:\n",
    "        st_time, ed_time = trial\n",
    "        viewbin_data_trial = viewbin_data[(viewbin_data[:,0] >= st_time) & (viewbin_data[:,0] < ed_time)]\n",
    "        cueimg_filter.append(viewbin_data_trial[:,1] == 1)\n",
    "        timebins_cue.append(np.hstack([viewbin_data_trial[:,0].reshape(-1,1), viewbin_data_trial[:,0].reshape(-1,1)+time_res]))\n",
    "        spikecounts_cue.append(np.zeros((viewbin_data_trial.shape[0], num_cells)))\n",
    "\n",
    "    # Slot spikes into cue phase intervals, using time bin resolution same as eyelink/raycasting data (i.e. 1 ms)\n",
    "    # Also filter out time bins where cue image was not looked at\n",
    "    for i, trial in enumerate(timebins_cue):\n",
    "        spikecounts_cue[i] = np.array(spike_counts_per_observation(trial, spike_times))\n",
    "        spikecounts_cue[i] = spikecounts_cue[i][cueimg_filter[i]]\n",
    "\n",
    "    # Convert spike counts to average spike rates across duration of cue phase\n",
    "    spikerates_cue = np.empty((len(spikecounts_cue), num_cells))\n",
    "    spikerates_cue[:,:] = np.nan\n",
    "    for i, trial in enumerate(spikecounts_cue):\n",
    "        if timebins_cue[i].shape[0] > 0:\n",
    "            spikerates_cue[i,:] = np.sum(trial, axis=0)/(time_res*timebins_cue[i].shape[0])\n",
    "\n",
    "    # Filter out trials with nans in cue spike rates\n",
    "    goals_cue = trial_markers.copy()\n",
    "    trajectories_cue = trial_trajectories.copy()\n",
    "    cue_filter = np.all(np.isfinite(spikerates_cue),axis=1)\n",
    "    spikerates_cue = spikerates_cue[cue_filter,:]\n",
    "    goals_cue = goals_cue[cue_filter]\n",
    "    trajectories_cue = trajectories_cue[cue_filter]\n",
    "\n",
    "    # Package variables for saving\n",
    "    cue_mean = {'spikerates_cue': spikerates_cue, 'goals_cue': goals_cue, 'trajectories_cue': trajectories_cue}\n",
    "\n",
    "\n",
    "    ### Hint views, mean over hint image views ###\n",
    "\n",
    "    timebins_hints = list()\n",
    "    spikecounts_hints = list()\n",
    "    for trial in nav_intervals:\n",
    "        st_time, ed_time = trial\n",
    "        viewbin_data_trial = viewbin_data[(viewbin_data[:,0] >= st_time) & (viewbin_data[:,0] < ed_time)]\n",
    "        hint_periods_trial = chunk_into_intervals(viewbin_data_trial[viewbin_data_trial[:,1] == 2, 0])\n",
    "        timebins_hints.append(hint_periods_trial)\n",
    "        spikecounts_hints.append(np.zeros((hint_periods_trial.shape[0], num_cells)))\n",
    "\n",
    "    # Slot spikes into hint viewing periods\n",
    "    for i, trial in enumerate(timebins_hints):\n",
    "        spikecounts_hints[i] = np.array(spike_counts_per_observation(trial, spike_times))\n",
    "\n",
    "    # Convert spike counts to average spike rates across all hint viewing instances per trial\n",
    "    spikerates_hints = np.empty((len(spikecounts_hints), num_cells))\n",
    "    spikerates_hints[:,:] = np.nan\n",
    "    for i, trial in enumerate(spikecounts_hints):\n",
    "        if timebins_hints[i].shape[0] > 0:\n",
    "            spikerates_hints[i,:] = np.sum(trial, axis=0)/np.sum(timebins_cue[i][:,1]-timebins_cue[i][:,0])\n",
    "    goals_hints = trial_markers.copy()\n",
    "    trajectories_hints = trial_trajectories.copy()\n",
    "\n",
    "    # Filter out trials with nans in hint spike rates\n",
    "    hints_filter = np.all(np.isfinite(spikerates_hints),axis=1)\n",
    "    spikerates_hints = spikerates_hints[hints_filter,:]\n",
    "    goals_hints = goals_hints[hints_filter]\n",
    "    trajectories_hints = trajectories_hints[hints_filter]\n",
    "\n",
    "    # Package variables for saving\n",
    "    hint_mean = {'spikerates_hints': spikerates_hints, 'goals_hints': goals_hints, 'trajectories_hints': trajectories_hints}\n",
    "\n",
    "\n",
    "    ### Nav end phase, mean over poster views ###\n",
    "\n",
    "    # Get last 1 second of navigation phases, but filter out unsuccessful trials\n",
    "    one_second = 1\n",
    "    successful_trials = np.where(trial_outcomes == 1)\n",
    "\n",
    "    # Filter out time points in the 1 second where the poster was not looked at\n",
    "    poster_filter = list()\n",
    "    timebins_navend = list()\n",
    "    spikecounts_navend = list()\n",
    "    for trial in nav_intervals:\n",
    "        st_time, ed_time = trial\n",
    "        st_time = ed_time - one_second\n",
    "        viewbin_data_trial = viewbin_data[(viewbin_data[:,0] >= st_time) & (viewbin_data[:,0] < ed_time)]\n",
    "        poster_filter.append(np.array([viewbin_data_trial[i,1] in poster_viewbins for i in range(viewbin_data_trial.shape[0])]))\n",
    "        timebins_navend.append(np.hstack([viewbin_data_trial[:,0].reshape(-1,1), viewbin_data_trial[:,0].reshape(-1,1)+tbin_size]))\n",
    "        spikecounts_navend.append(np.zeros((viewbin_data_trial.shape[0], num_cells)))\n",
    "\n",
    "    # Slot spikes into navend intervals, using time bin resolution same as eyelink/raycasting data (i.e. 1 ms)\n",
    "    # Also filter out time bins where poster was not looked at\n",
    "    for i, trial in enumerate(timebins_navend):\n",
    "        spikecounts_navend[i] = np.array(spike_counts_per_observation(trial, spike_times))\n",
    "        if poster_filter[i].shape[0] > 0:\n",
    "            spikecounts_navend[i] = spikecounts_navend[i][poster_filter[i]]\n",
    "\n",
    "    # Convert spike counts to average spike rates across duration of cue phase\n",
    "    spikerates_navend = np.empty((len(spikecounts_navend), num_cells))\n",
    "    spikerates_navend[:,:] = np.nan\n",
    "    for i, trial in enumerate(spikecounts_navend):\n",
    "        if timebins_navend[i].shape[0] > 0:\n",
    "            spikerates_navend[i,:] = np.sum(trial, axis=0)/(tbin_size*timebins_navend[i].shape[0])\n",
    "\n",
    "    # Filter out trials with nans in navend spike rates\n",
    "    goals_navend = trial_markers.copy()\n",
    "    trajectories_navend = trial_trajectories.copy()\n",
    "    navend_filter = np.all(np.isfinite(spikerates_navend),axis=1)\n",
    "    spikerates_navend = spikerates_navend[navend_filter,:]\n",
    "    goals_navend = goals_navend[navend_filter]\n",
    "    trajectories_navend = trajectories_navend[navend_filter]\n",
    "\n",
    "    # Package variables for saving\n",
    "    navend_mean = {'spikerates_navend': spikerates_navend, 'goals_navend': goals_navend, 'trajectories_navend': trajectories_navend}\n",
    "\n",
    "\n",
    "    ### Inter-trial intervals, 100ms time bins ###\n",
    "\n",
    "    # Preallocate list of arrays for spike counts per time bin in cue phase\n",
    "    # Then slot spikes into cue phase intervals, using time bin resolution specified by tbin_size\n",
    "    timebins_iti, spikecounts_iti = list(), list()\n",
    "    for trial in iti_intervals:\n",
    "        st_time, ed_time = trial\n",
    "        st_time = ed_time - 2 * one_second\n",
    "        timebins_iti_trial = np.hstack([np.arange(st_time, ed_time, tbin_size).reshape(-1,1), np.arange(st_time, ed_time, tbin_size).reshape(-1,1) + tbin_size])\n",
    "        timebins_iti.append(timebins_iti_trial)\n",
    "        spikecounts_iti.append(np.array(spike_counts_per_observation(timebins_iti_trial, spike_times)))\n",
    "\n",
    "    # Convert spike counts to average spike rates across duration of cue phase\n",
    "    spikerates_iti = [trial/tbin_size for trial in spikecounts_iti]\n",
    "\n",
    "    # Filter out trials with nans in cue spike rates\n",
    "    goals_iti = trial_markers.copy()\n",
    "    trajectories_iti = trial_trajectories.copy()\n",
    "\n",
    "    # Package variables for saving\n",
    "    iti_100ms = {'spikerates_iti': spikerates_iti, 'goals_iti': goals_iti, 'trajectories_iti': trajectories_iti}\n",
    "\n",
    "\n",
    "    ### Nav end phase, 100ms time bins ###\n",
    "\n",
    "    # Preallocate list of arrays for spike counts per time bin in cue phase\n",
    "    # Then slot spikes into cue phase intervals, using time bin resolution specified by tbin_size\n",
    "    timebins_navend, spikecounts_navend = list(), list()\n",
    "    for trial in nav_intervals:\n",
    "        st_time, ed_time = trial\n",
    "        st_time = ed_time - one_second\n",
    "        timebins_navend_trial = np.hstack([np.arange(st_time, ed_time, tbin_size).reshape(-1,1), np.arange(st_time, ed_time, tbin_size).reshape(-1,1) + tbin_size])\n",
    "        timebins_navend.append(timebins_navend_trial)\n",
    "        spikecounts_navend.append(np.array(spike_counts_per_observation(timebins_navend_trial, spike_times)))\n",
    "\n",
    "    # Convert spike counts to average spike rates across duration of cue phase\n",
    "    spikerates_navend = [trial/tbin_size for trial in spikecounts_navend]\n",
    "\n",
    "    # Filter out trials with nans in cue spike rates\n",
    "    goals_navend = trial_markers.copy()\n",
    "    trajectories_navend = trial_trajectories.copy()\n",
    "\n",
    "    # Package variables for saving\n",
    "    navend_100ms = {'spikerates_navend': spikerates_navend, 'goals_navend': goals_navend, 'trajectories_navend': trajectories_navend}\n",
    "\n",
    "\n",
    "    ### Nav start phase, 100ms time bins ###\n",
    "\n",
    "    # Preallocate list of arrays for spike counts per time bin in cue phase\n",
    "    # Then slot spikes into cue phase intervals, using time bin resolution specified by tbin_size\n",
    "    timebins_navst, spikecounts_navst = list(), list()\n",
    "    for trial in nav_intervals:\n",
    "        st_time, ed_time = trial\n",
    "        ed_time = st_time + one_second\n",
    "        timebins_navst_trial = np.hstack([np.arange(st_time, ed_time, tbin_size).reshape(-1,1), np.arange(st_time, ed_time, tbin_size).reshape(-1,1) + tbin_size])\n",
    "        timebins_navst.append(timebins_navst_trial)\n",
    "        spikecounts_navst.append(np.array(spike_counts_per_observation(timebins_navst_trial, spike_times)))\n",
    "\n",
    "    # Convert spike counts to average spike rates across duration of cue phase\n",
    "    spikerates_navst = [trial/tbin_size for trial in spikecounts_navst]\n",
    "\n",
    "    # Filter out trials with nans in cue spike rates\n",
    "    goals_navst = trial_markers.copy()\n",
    "    trajectories_navst = trial_trajectories.copy()\n",
    "\n",
    "    # Package variables for saving\n",
    "    navst_100ms = {'spikerates_navst': spikerates_navst, 'goals_navst': goals_navst, 'trajectories_navst': trajectories_navst}\n",
    "\n",
    "\n",
    "    ### Save processed data to pkl file ###\n",
    "    for i, label in enumerate(cell_labels):\n",
    "        label = label.split('/')\n",
    "        label[1] = label[1][2:]\n",
    "        if label[1][0] == '0':\n",
    "            label[1] = label[1][1:]\n",
    "        cell_labels[i] = f'{day_dir}ch{label[1]}{label[2]}'\n",
    "\n",
    "    data = {'cue_mean': cue_mean, 'hint_mean': hint_mean, 'navend_mean': navend_mean, 'cue_100ms': cue_100ms, 'navst_100ms': navst_100ms, 'navend_100ms': navend_100ms, 'iti_100ms': iti_100ms,\\\n",
    "            'cell_labels': cell_labels}\n",
    "    with open(f'{save_dir}/{day_dir}_data.pkl', 'wb') as file:\n",
    "        pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day_dir in day_list:\n",
    "    if os.path.exists(f'{save_dir}_50ms/{day_dir}_data.pkl') and not overwrite:\n",
    "        continue\n",
    "\n",
    "    ### Load in data from files ###\n",
    "\n",
    "    # Get list of cells under the day directory\n",
    "    os.system(f\"sh ~/Documents/neural_decoding/Hippocampus_Decoding/get_cells.sh {day_dir}\")\n",
    "    cell_list = list()\n",
    "    with open(\"cell_list.txt\", \"r\") as file:\n",
    "        for line in file.readlines():\n",
    "            cell_list.append(line.strip())\n",
    "    os.system(\"rm cell_list.txt\")\n",
    "\n",
    "    # Load data from rplparallel.mat object, extract trial markers, time stamps and session start timestamp\n",
    "    rp_file = h5py.File(prefix + day_dir + \"/session01/rplparallel.mat\")\n",
    "    rp = rp_file.get('rp').get('data')\n",
    "    trial_markers = np.array(rp.get('markers'))\n",
    "    trial_timestamps = np.round(np.array(rp.get('timeStamps')), 3)\n",
    "    session_start_time = np.round(np.array(rp.get('session_start_sec'))[0,0], 3)\n",
    "    rp_file.close()\n",
    "\n",
    "    # Load data and extract spike times from all spiketrain.mat objects\n",
    "    spike_times = list()\n",
    "    cell_labels = list()\n",
    "    for cell_dir in cell_list:\n",
    "        try:\n",
    "            spk_file = loadmat(prefix + day_dir + \"/session01/\" + cell_dir + \"/spiketrain.mat\")\n",
    "        except NotImplementedError:\n",
    "            spk_file = h5py.File(prefix + day_dir + \"/session01/\" + cell_dir + \"/spiketrain.mat\")\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        spk = np.array(spk_file.get('timestamps')).flatten() # spike timestamps is loaded in as a column vector\n",
    "        spk /= 1000 # convert spike timestamps from msec to sec\n",
    "        spike_times.append(spk)\n",
    "        if isinstance(spk_file, h5py.File):\n",
    "            spk_file.close()\n",
    "        \n",
    "        cell_name = cell_dir.split('/')\n",
    "        array, channel, cell = cell_name[0][6:], cell_name[1][7:], cell_name[2][5:]\n",
    "        if channel[0] == '0':\n",
    "            channel = channel[1:]\n",
    "        cell_labels.append(f'a{array}/ch{channel}/c{cell}')\n",
    "\n",
    "    # Load data from vmpv.mat object, extract session end timestamp\n",
    "    pv_file = h5py.File(prefix + day_dir + \"/session01/1vmpv.mat\")\n",
    "    pv = pv_file.get('pv').get('data')\n",
    "    session_end_time = np.round(np.array(pv.get('rplmaxtime'))[0,0], 3)\n",
    "    pv_file.close()\n",
    "\n",
    "\n",
    "    ### Data preprocessing ###\n",
    "\n",
    "    # Define important constants\n",
    "    num_cells = len(cell_labels)\n",
    "    num_goals = 6\n",
    "    time_res = 0.001\n",
    "    tbin_size = 0.05\n",
    "\n",
    "    # Get trial outcomes from trial markers\n",
    "    # 0 for unsuccessful trials, 1 for successful trials\n",
    "    trial_outcomes = 4 - trial_markers[2,:] // 10\n",
    "    trial_outcomes = trial_outcomes.astype(int)\n",
    "\n",
    "    # Get poster numbers from trial markers, cue phase time intervals\n",
    "    trial_markers = trial_markers[0,:] % 10\n",
    "    trial_markers = trial_markers.astype(int)\n",
    "    cue_intervals = trial_timestamps[0:2,:].T\n",
    "\n",
    "    # Get durations of each navigation phase\n",
    "    nav_intervals = trial_timestamps[1:,:].T\n",
    "    nav_durations = nav_intervals[:,1] - nav_intervals[:,0]\n",
    "\n",
    "    # Generate time intervals for each trial\n",
    "    trial_intervals = np.empty_like(cue_intervals)\n",
    "    trial_intervals[:,0] = cue_intervals[:,1]\n",
    "    trial_intervals[:-1,1] = cue_intervals[1:,0]\n",
    "    trial_intervals[-1,1] = session_end_time\n",
    "\n",
    "    # Generate time intervals for each inter-trial interval\n",
    "    iti_intervals = np.empty_like(cue_intervals)\n",
    "    iti_intervals[:,0] = nav_intervals[:,1]\n",
    "    iti_intervals[:-1,1] = cue_intervals[1:,0]\n",
    "    iti_intervals[-1,1] = session_end_time\n",
    "\n",
    "    # Further differentiate trial markers into trial trajectories (start poster, end poster)\n",
    "    trial_trajectories = np.zeros((trial_markers.shape[0], 2))\n",
    "    trial_trajectories[:,1] = trial_markers\n",
    "    trial_trajectories[1:,0] = trial_markers[:-1]\n",
    "\n",
    "    # Filter out trials that are too long (> 25 seconds) or have repeated goal from previous trial\n",
    "    good_trials = np.ones(trial_markers.shape, dtype=np.int8)\n",
    "    max_dur = 25  # maximum duration of trials (in seconds) to filter out\n",
    "    prev_goal = 0\n",
    "    for num, dur in enumerate(nav_durations):\n",
    "        curr_goal = trial_markers[num]\n",
    "        if dur > max_dur or curr_goal == prev_goal:\n",
    "            good_trials[num] = 0\n",
    "        prev_goal = curr_goal\n",
    "    trial_filt = np.where(good_trials == 1)\n",
    "\n",
    "    trial_outcomes = trial_outcomes[trial_filt]\n",
    "    trial_markers = trial_markers[trial_filt]\n",
    "    cue_intervals = cue_intervals[trial_filt]\n",
    "    nav_intervals = nav_intervals[trial_filt]\n",
    "    nav_durations = nav_durations[trial_filt]\n",
    "    trial_intervals = trial_intervals[trial_filt]\n",
    "    iti_intervals = iti_intervals[trial_filt]\n",
    "    trial_trajectories = trial_trajectories[trial_filt]\n",
    "\n",
    "\n",
    "    ### Cue phase, 50 ms time bins ###\n",
    "\n",
    "    # Preallocate list of arrays for spike counts per time bin in cue phase\n",
    "    # Then slot spikes into cue phase intervals, using time bin resolution specified by tbin_size\n",
    "    timebins_cue, spikecounts_cue = list(), list()\n",
    "    for trial in cue_intervals:\n",
    "        st_time, ed_time = trial\n",
    "        ed_time = st_time + one_second\n",
    "        timebins_cue_trial = np.hstack([np.arange(st_time, ed_time, tbin_size).reshape(-1,1), np.arange(st_time, ed_time, tbin_size).reshape(-1,1) + tbin_size])\n",
    "        timebins_cue.append(timebins_cue_trial)\n",
    "        spikecounts_cue.append(np.array(spike_counts_per_observation(timebins_cue_trial, spike_times)))\n",
    "\n",
    "    # Convert spike counts to average spike rates across duration of cue phase\n",
    "    spikerates_cue = [trial/tbin_size for trial in spikecounts_cue]\n",
    "\n",
    "    # Filter out trials with nans in cue spike rates\n",
    "    goals_cue = trial_markers.copy()\n",
    "    trajectories_cue = trial_trajectories.copy()\n",
    "\n",
    "    # Package variables for saving\n",
    "    cue_50ms = {'spikerates_cue': spikerates_cue, 'goals_cue': goals_cue, 'trajectories_cue': trajectories_cue}\n",
    "\n",
    "\n",
    "    ### Inter-trial intervals, 50ms time bins ###\n",
    "\n",
    "    # Preallocate list of arrays for spike counts per time bin in cue phase\n",
    "    # Then slot spikes into cue phase intervals, using time bin resolution specified by tbin_size\n",
    "    timebins_iti, spikecounts_iti = list(), list()\n",
    "    for trial in iti_intervals:\n",
    "        st_time, ed_time = trial\n",
    "        st_time = ed_time - 2 * one_second\n",
    "        timebins_iti_trial = np.hstack([np.arange(st_time, ed_time, tbin_size).reshape(-1,1), np.arange(st_time, ed_time, tbin_size).reshape(-1,1) + tbin_size])\n",
    "        timebins_iti.append(timebins_iti_trial)\n",
    "        spikecounts_iti.append(np.array(spike_counts_per_observation(timebins_iti_trial, spike_times)))\n",
    "\n",
    "    # Convert spike counts to average spike rates across duration of cue phase\n",
    "    spikerates_iti = [trial/tbin_size for trial in spikecounts_iti]\n",
    "\n",
    "    # Filter out trials with nans in cue spike rates\n",
    "    goals_iti = trial_markers.copy()\n",
    "    trajectories_iti = trial_trajectories.copy()\n",
    "\n",
    "    # Package variables for saving\n",
    "    iti_50ms = {'spikerates_iti': spikerates_iti, 'goals_iti': goals_iti, 'trajectories_iti': trajectories_iti}\n",
    "\n",
    "\n",
    "    ### Nav end phase, 50ms time bins ###\n",
    "\n",
    "    # Preallocate list of arrays for spike counts per time bin in cue phase\n",
    "    # Then slot spikes into cue phase intervals, using time bin resolution specified by tbin_size\n",
    "    timebins_navend, spikecounts_navend = list(), list()\n",
    "    for trial in nav_intervals:\n",
    "        st_time, ed_time = trial\n",
    "        st_time = ed_time - one_second\n",
    "        timebins_navend_trial = np.hstack([np.arange(st_time, ed_time, tbin_size).reshape(-1,1), np.arange(st_time, ed_time, tbin_size).reshape(-1,1) + tbin_size])\n",
    "        timebins_navend.append(timebins_navend_trial)\n",
    "        spikecounts_navend.append(np.array(spike_counts_per_observation(timebins_navend_trial, spike_times)))\n",
    "\n",
    "    # Convert spike counts to average spike rates across duration of cue phase\n",
    "    spikerates_navend = [trial/tbin_size for trial in spikecounts_navend]\n",
    "\n",
    "    # Filter out trials with nans in cue spike rates\n",
    "    goals_navend = trial_markers.copy()\n",
    "    trajectories_navend = trial_trajectories.copy()\n",
    "\n",
    "    # Package variables for saving\n",
    "    navend_50ms = {'spikerates_navend': spikerates_navend, 'goals_navend': goals_navend, 'trajectories_navend': trajectories_navend}\n",
    "\n",
    "\n",
    "    ### Nav start phase, 50ms time bins ###\n",
    "\n",
    "    # Preallocate list of arrays for spike counts per time bin in cue phase\n",
    "    # Then slot spikes into cue phase intervals, using time bin resolution specified by tbin_size\n",
    "    timebins_navst, spikecounts_navst = list(), list()\n",
    "    for trial in nav_intervals:\n",
    "        st_time, ed_time = trial\n",
    "        ed_time = st_time + one_second\n",
    "        timebins_navst_trial = np.hstack([np.arange(st_time, ed_time, tbin_size).reshape(-1,1), np.arange(st_time, ed_time, tbin_size).reshape(-1,1) + tbin_size])\n",
    "        timebins_navst.append(timebins_navst_trial)\n",
    "        spikecounts_navst.append(np.array(spike_counts_per_observation(timebins_navst_trial, spike_times)))\n",
    "\n",
    "    # Convert spike counts to average spike rates across duration of cue phase\n",
    "    spikerates_navst = [trial/tbin_size for trial in spikecounts_navst]\n",
    "\n",
    "    # Filter out trials with nans in cue spike rates\n",
    "    goals_navst = trial_markers.copy()\n",
    "    trajectories_navst = trial_trajectories.copy()\n",
    "\n",
    "    # Package variables for saving\n",
    "    navst_50ms = {'spikerates_navst': spikerates_navst, 'goals_navst': goals_navst, 'trajectories_navst': trajectories_navst}\n",
    "\n",
    "\n",
    "    ### Save processed data to pkl file ###\n",
    "    for i, label in enumerate(cell_labels):\n",
    "        label = label.split('/')\n",
    "        label[1] = label[1][2:]\n",
    "        if label[1][0] == '0':\n",
    "            label[1] = label[1][1:]\n",
    "        cell_labels[i] = f'{day_dir}ch{label[1]}{label[2]}'\n",
    "\n",
    "    data = {'cue_50ms': cue_50ms, 'navst_50ms': navst_50ms, 'navend_50ms': navend_50ms, 'iti_50ms': iti_50ms,\\\n",
    "            'cell_labels': cell_labels}\n",
    "    with open(f'{save_dir}_50ms/{day_dir}_data.pkl', 'wb') as file:\n",
    "        pickle.dump(data, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decoding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
