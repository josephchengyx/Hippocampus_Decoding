{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import h5py\n",
    "from preproc import *\n",
    "from priordist import PriorDistributionCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which day's dataset to use\n",
    "prefix = \"/Volumes/Hippocampus/Data/picasso-misc/\"\n",
    "day_dir = \"20181102\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of cells under the day directory\n",
    "os.system(f\"sh ~/Documents/neural_decoding/Hippocampus_Decoding/get_cells.sh {day_dir}\")\n",
    "cell_list = list()\n",
    "with open(\"cell_list.txt\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        cell_list.append(line.strip())\n",
    "os.system(\"rm cell_list.txt\")\n",
    "\n",
    "# Load data from rplparallel.mat object, extract trial markers, time stamps and session start timestamp\n",
    "rp = h5py.File(prefix + day_dir + \"/session01/rplparallel.mat\")\n",
    "rp = rp.get('rp').get('data')\n",
    "trial_markers = np.array(rp.get('markers'))\n",
    "trial_timestamps = np.array(rp.get('timeStamps'))\n",
    "session_start_time = np.round(np.array(rp.get('session_start_sec'))[0,0], 3)\n",
    "\n",
    "# Load data and extract spike times from all spiketrain.mat objects\n",
    "spike_times = list()\n",
    "cell_labels = list()\n",
    "for cell_dir in cell_list:\n",
    "    spk = loadmat(prefix + day_dir + \"/session01/\" + cell_dir + \"/spiketrain.mat\")\n",
    "    spk = spk.get('timestamps').flatten() # spike timestamps is loaded in as a column vector\n",
    "    spk = spk / 1000 # convert spike timestamps from msec to sec\n",
    "    spike_times.append(spk)\n",
    "    \n",
    "    cell_name = cell_dir.split('/')\n",
    "    array, channel, cell = cell_name[0][6:], cell_name[1][7:], cell_name[2][5:]\n",
    "    if channel[0] == '0':\n",
    "        channel = channel[1:]\n",
    "    cell_labels.append(f'a{array}/ch{channel}/c{cell}')\n",
    "\n",
    "# Load data from vmpv.mat object, extract session end timestamp\n",
    "pv = h5py.File(prefix + day_dir + \"/session01/1vmpv.mat\")\n",
    "pv = pv.get('pv').get('data')\n",
    "session_end_time = np.round(np.array(pv.get('rplmaxtime'))[0,0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check outcomes of each trial\n",
    "trial_outcomes = np.array(rp.get('markers'))\n",
    "trial_outcomes = trial_outcomes[2,:] // 10\n",
    "trial_outcomes = trial_outcomes.astype(int)\n",
    "\n",
    "# Get frequencies of trial outcomes\n",
    "trial_outcomes_freq = dict()\n",
    "for trial in trial_outcomes:\n",
    "    if trial not in trial_outcomes_freq:\n",
    "        trial_outcomes_freq[trial] = 1\n",
    "    else:\n",
    "        trial_outcomes_freq[trial] += 1\n",
    "\n",
    "print(trial_outcomes_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get poster numbers from trial markers, cue phase time intervals\n",
    "trial_markers = trial_markers[0,:] % 10\n",
    "trial_markers = trial_markers.astype(int)\n",
    "cue_intervals = trial_timestamps[0:2,:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate time intervals for navigation phases\n",
    "nav_timestamps = trial_timestamps[1:,:].T\n",
    "\n",
    "# Bin navigation phases into 250 ms time bins\n",
    "nav_intervals = list()\n",
    "delta = 0.25  # Size of time bin (in seconds)\n",
    "for idx, intvl in enumerate(nav_timestamps):\n",
    "    nav_start, nav_end = intvl\n",
    "    nav_intervals.append(np.vstack((np.arange(nav_start, nav_end - delta, delta), np.arange(nav_start + delta, nav_end, delta))).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate time intervals for each trial\n",
    "trial_intervals = np.empty_like(cue_intervals)\n",
    "trial_intervals[:,0] = cue_intervals[:,1]\n",
    "trial_intervals[:-1,1] = cue_intervals[1:,0]\n",
    "trial_intervals[-1,1] = session_end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of time bins per trial\n",
    "timebins_per_nav_phase = np.array(list(map(lambda arr: int(arr.shape[0] * delta), nav_intervals)))\n",
    "\n",
    "# Filter out trials that are too long (> 25 seconds) or have repeated goal from previous trial\n",
    "good_trials = np.ones(timebins_per_nav_phase.shape, dtype=np.int8)\n",
    "min_dur, max_dur = 2, 25  # minimum and maximum duration of trials (in seconds) to filter out\n",
    "\n",
    "prev_goal = 0\n",
    "for num, dur in enumerate(timebins_per_nav_phase):\n",
    "    curr_goal = trial_markers[num]\n",
    "    if dur > max_dur or curr_goal == prev_goal:\n",
    "        good_trials[num] = 0\n",
    "    prev_goal = curr_goal\n",
    "# for num, dur in enumerate(timebins_per_nav_phase):\n",
    "#     if dur < min_dur or dur > max_dur:\n",
    "#         good_trials[num] = 0\n",
    "trial_filt = np.where(good_trials == 1)\n",
    "\n",
    "trial_markers = trial_markers[trial_filt]\n",
    "cue_intervals = cue_intervals[trial_filt,:][0]  # not sure why it adds an extra axis\n",
    "new_nav_intervals = list()\n",
    "for num, trial in enumerate(nav_intervals):\n",
    "    if good_trials[num] == 1:\n",
    "        new_nav_intervals.append(trial)\n",
    "nav_intervals = new_nav_intervals\n",
    "timebins_per_nav_phase = timebins_per_nav_phase[trial_filt]\n",
    "trial_intervals = trial_intervals[trial_filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pool cue phase and navigation phase intervals together to get session intervals\n",
    "# session_intervals = list()\n",
    "# for num, nav_phase in enumerate(nav_intervals):\n",
    "#     session_intervals.append(cue_intervals[num])\n",
    "#     for intvl in nav_phase:\n",
    "#         session_intervals.append(intvl)\n",
    "# session_intervals = np.array(session_intervals)\n",
    "\n",
    "# Bin entire session into 250 ms time bins, aligned to the end of each cue phase for each trial\n",
    "session_intervals = list()\n",
    "# delta = 0.25  # Size of time bin, already defined earlier\n",
    "for idx, intvl in enumerate(trial_intervals):\n",
    "    cue_start, cue_end = cue_intervals[idx,:]\n",
    "    for time in np.arange(cue_start, cue_end - delta, delta):\n",
    "        session_intervals.append(np.array([time, time + delta]))\n",
    "    nav_start, nav_end = intvl\n",
    "    for time in np.arange(nav_start, nav_end - delta, delta):\n",
    "        session_intervals.append(np.array([time, time + delta]))\n",
    "session_intervals = np.array(session_intervals)\n",
    "\n",
    "# Generate cue intervals binned into 250 ms time bins\n",
    "num_prds = int(1/delta)\n",
    "new_cue_intervals = np.empty((cue_intervals.shape[0]*num_prds, cue_intervals.shape[1]))\n",
    "for idx, intvl in enumerate(cue_intervals):\n",
    "    cue_start, cue_end = intvl\n",
    "    for prd in range(num_prds):\n",
    "        new_cue_intervals[idx+prd,0] = cue_start + delta * prd\n",
    "        new_cue_intervals[idx+prd,1] = cue_start + delta * (prd + 1)\n",
    "full_cue_intervals = cue_intervals\n",
    "cue_intervals = new_cue_intervals\n",
    "\n",
    "# Custom trial markers array for cue intervals\n",
    "trial_markers_x4 = np.zeros(trial_markers.shape[0] * num_prds)\n",
    "for idx, marker in enumerate(trial_markers):\n",
    "    for prd in range(num_prds):\n",
    "        trial_markers_x4[idx+prd] = marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of cells in dataset\n",
    "num_cells = len(cell_labels)\n",
    "\n",
    "# Slot spikes into cue phase intervals\n",
    "spikecounts_cue = spike_counts_per_observation(cue_intervals, spike_times)\n",
    "\n",
    "# Slot spikes into navigation phase intervals\n",
    "spikecounts_nav = list()\n",
    "for phase in nav_intervals:\n",
    "    spikecounts_nav.append(spike_counts_per_observation(phase, spike_times))\n",
    "\n",
    "# Slot spikes into session time intervals\n",
    "spikecounts_session = spike_counts_per_observation(session_intervals, spike_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin spike counts within each cell for entire sesion, and get firing rate thresholds used for binning\n",
    "binned_spikes_session = np.empty_like(spikecounts_session)\n",
    "binning_stats = list()\n",
    "for col in range(spikecounts_session.shape[1]):\n",
    "    binned_spikes_session[:,col] = bin_firing_rates_4(spikecounts_session[:,col])\n",
    "    binning_stats.append(get_binning_stats_4(spikecounts_session[:,col]))\n",
    "\n",
    "# Bin spike counts within each cell for cue phases\n",
    "binned_spikes_cue = np.empty_like(spikecounts_cue)\n",
    "for col in range(spikecounts_cue.shape[1]):\n",
    "    binned_spikes_cue[:,col] = bin_firing_rates_4(spikecounts_cue[:,col], stats=binning_stats[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of trial durations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Trial Durations')\n",
    "plt.hist(timebins_per_nav_phase, bins=25)\n",
    "plt.xlabel('Duration (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get quantiles of trial duration distribution\n",
    "trial_dur_25 = np.percentile(timebins_per_nav_phase, 25)\n",
    "trial_dur_50 = np.median(timebins_per_nav_phase)\n",
    "trial_dur_75 = np.percentile(timebins_per_nav_phase, 75)\n",
    "trial_dur_min = min(timebins_per_nav_phase)\n",
    "\n",
    "print(f'Percentage of trials longer than __ seconds (sample size: {timebins_per_nav_phase.shape[0]}):')\n",
    "print(f'25%: {trial_dur_75}, 50%: {trial_dur_50}, 75%: {trial_dur_25}, min: {trial_dur_min}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_goal(timeseries: np.array, goals: np.array) -> list:\n",
    "    num_goals = 6\n",
    "    grouped = [np.empty((0, timeseries.shape[1])) for _ in range(num_goals)]\n",
    "    for idx, goal in enumerate(goals):\n",
    "        goal = int(goal - 1)\n",
    "        grouped[goal] = np.vstack((grouped[goal], timeseries[idx,:]))\n",
    "    return grouped\n",
    "\n",
    "def information_gain(response_dist: PriorDistributionCell, constants: tuple) -> np.array:\n",
    "    num_goals, num_cells, num_cats = constants\n",
    "    info_gain = np.zeros((num_goals, num_cells))\n",
    "    for goal in range(num_goals):\n",
    "        for cell in range(num_cells):\n",
    "            for cat in range(num_cats):\n",
    "                P_r_s = response_dist.P_r_s(cell, cat, goal)\n",
    "                P_r = response_dist.P_r(cell, cat)\n",
    "                if P_r_s != 0:\n",
    "                    info_gain[goal, cell] += P_r_s * np.log2(P_r_s / P_r)\n",
    "    return info_gain\n",
    "\n",
    "def net_information_gain(info_gain: np.array, response_dist: PriorDistributionCell, constants: tuple) -> np.array:\n",
    "    num_goals, num_cells, num_cats = constants\n",
    "    net_info_gain = np.zeros(num_cells)\n",
    "    for cell in range(num_cells):\n",
    "        for goal in range(num_goals):\n",
    "            I_s_R = info_gain[goal, cell]\n",
    "            P_s = response_dist.P_s(goal)\n",
    "            net_info_gain[cell] += P_s * I_s_R\n",
    "    return net_info_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_information_gain_calc(data: tuple, constants: tuple) -> np.array:\n",
    "    # Unpacking main data variables and constants\n",
    "    binned_spikes_nav, binned_spikes_session, trial_markers = data\n",
    "    num_goals, num_cells, num_cats = constants\n",
    "\n",
    "    # Group cue phase spikes according to goal\n",
    "    responses_per_goal_nav = group_by_goal(binned_spikes_nav, trial_markers)\n",
    "\n",
    "    # Get distribution of population responses for cue phase and navigation phase vs entire session\n",
    "    response_distribution_nav = PriorDistributionCell(binned_spikes_session, responses_per_goal_nav)\n",
    "\n",
    "    # Information gain per stimulus (relative to entire session responses)\n",
    "    information_gain_nav = information_gain(response_distribution_nav, constants)\n",
    "\n",
    "    # Net information gain acrosss entire stimuli set\n",
    "    net_information_gain_nav = net_information_gain(information_gain_nav, response_distribution_nav, constants)\n",
    "    return net_information_gain_nav\n",
    "\n",
    "\n",
    "def bootstrap_estimate(data: tuple, constants: tuple, ratio: float, iters: int, intvl: tuple, replace=True, rng=np.random.default_rng()) -> tuple:\n",
    "    # Unpack main data variables\n",
    "    binned_spikes_nav, binned_spikes_session, trial_markers = data\n",
    "\n",
    "    # Store net information gain ratio estimate from each bootstrapped sample\n",
    "    estimates = list()\n",
    "\n",
    "    # Big loop\n",
    "    for i in range(iters):\n",
    "        # Sampling with replacement\n",
    "        num_samples = binned_spikes_nav.shape[0]\n",
    "        num_subset = int(round(ratio * num_samples))\n",
    "        indexes = tuple(rng.choice(num_samples, size=num_subset, replace=replace))\n",
    "        binned_spikes_nav_subset = binned_spikes_nav[indexes,:]\n",
    "        trial_markers_subset = trial_markers.reshape(-1,1)[indexes,:][:,0]\n",
    "\n",
    "        # Calculate net information gain ratio for this sample\n",
    "        data_subset = binned_spikes_nav_subset, binned_spikes_session, trial_markers_subset\n",
    "        estimates.append(net_information_gain_calc(data_subset, constants))\n",
    "\n",
    "    # Calculate bootstrapped mean and stdev\n",
    "    est_mean = np.mean(estimates, axis=0)\n",
    "    est_std = np.std(estimates, axis=0, ddof=1)\n",
    "    est_intvl = (np.percentile(estimates, intvl[0], axis=0), np.percentile(estimates, intvl[1], axis=0))\n",
    "    return est_mean, est_std, est_intvl\n",
    "\n",
    "\n",
    "def nav_net_information_gain(data: tuple, constants: tuple, boot_params: tuple, time_diff: float, res=dict()) -> dict:\n",
    "    # Unpacking main data variables and constants\n",
    "    binned_spikes_session, binning_stats, trial_markers, spikecounts_nav = data\n",
    "    num_goals, num_cells, num_cats = constants\n",
    "    boot_ratio, boot_iters, boot_intvl, boot_replace = boot_params\n",
    "\n",
    "    # Filter out trials with navigation phases less than time_diff seconds\n",
    "    filt = np.where(timebins_per_nav_phase >= time_diff)\n",
    "    trial_markers = trial_markers[filt]\n",
    "    spikecounts_nav = list(filter(lambda arr: arr.shape[0] >= time_diff, spikecounts_nav))\n",
    "\n",
    "    # Select time bin time_diff seconds after cue phase for each navigation phase\n",
    "    spikecounts_nav = np.array(list(map(lambda arr: arr[time_diff-1,:], spikecounts_nav)))\n",
    "\n",
    "    # Bin spike counts within each cell for navigation phases\n",
    "    binned_spikes_nav = np.empty_like(spikecounts_nav)\n",
    "    for col in range(spikecounts_nav.shape[1]):\n",
    "        binned_spikes_nav[:,col] = bin_firing_rates_4(spikecounts_nav[:,col], stats=binning_stats[col])\n",
    "\n",
    "    # Group cue phase spikes according to goal\n",
    "    responses_per_goal_nav = group_by_goal(binned_spikes_nav, trial_markers)\n",
    "\n",
    "    # Get distribution of population responses for cue phase and navigation phase vs entire session\n",
    "    response_distribution_nav = PriorDistributionCell(binned_spikes_session, responses_per_goal_nav)\n",
    "\n",
    "    # Information gain per stimulus (relative to entire session responses)\n",
    "    information_gain_nav = information_gain(response_distribution_nav, constants)\n",
    "\n",
    "    # Net information gain acrosss entire stimuli set\n",
    "    net_information_gain_nav = net_information_gain(information_gain_nav, response_distribution_nav, constants)\n",
    "\n",
    "    # Bootstrap estimate of error\n",
    "    boot_data = (binned_spikes_nav, binned_spikes_session, trial_markers)\n",
    "    boot_mean, boot_std, boot_intvl = bootstrap_estimate(boot_data, constants, boot_ratio, boot_iters, boot_intvl, replace=boot_replace)\n",
    "\n",
    "    # Write to result dictionary and return\n",
    "    res[time_diff] = (net_information_gain_nav, boot_intvl)\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some important constants\n",
    "num_goals = 6\n",
    "num_cells = len(cell_list)\n",
    "num_cats = 4\n",
    "\n",
    "# Pack session data\n",
    "session_data = (binned_spikes_session, binning_stats, trial_markers, spikecounts_nav)\n",
    "constants = (num_goals, num_cells, num_cats)\n",
    "\n",
    "# Set params for bootstrapping estimation\n",
    "boot_ratio = 0.8\n",
    "boot_iters = 1000\n",
    "boot_intvl = (1, 99)\n",
    "boot_replace = False\n",
    "boot_params = (boot_ratio, boot_iters, boot_intvl, boot_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate net informaiton gain across all cue phases\n",
    "responses_per_goal_cue = group_by_goal(binned_spikes_cue, trial_markers_x4)\n",
    "response_distribution_cue = PriorDistributionCell(binned_spikes_session, responses_per_goal_cue)\n",
    "information_gain_cue = information_gain(response_distribution_cue, constants)\n",
    "net_information_gain_cue = net_information_gain(information_gain_cue, response_distribution_cue, constants)\n",
    "cue_boot_mean, cue_boot_std, cue_boot_intvl = bootstrap_estimate((binned_spikes_cue, binned_spikes_session, trial_markers_x4), constants, boot_ratio, boot_iters, boot_intvl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shannon entropy across goals\n",
    "goal_entropy = 0\n",
    "for goal in range(num_goals):\n",
    "    P_s = response_distribution_cue.P_s(goal)\n",
    "    goal_entropy -= P_s * np.log2(P_s)\n",
    "\n",
    "print(f'{goal_entropy}, {np.log2(6)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run anaylsis across different time differences for navigation phase\n",
    "results = {0: (net_information_gain_cue, cue_boot_intvl)}\n",
    "# Get ratios of net information gain of cue against navigation phase\n",
    "results_ratio = dict()\n",
    "# Average ratio of net information gain between cue and navigation phase for each cell\n",
    "average_ratio = np.zeros(num_cells)\n",
    "\n",
    "for time_diff in range(1, int(trial_dur_50)+1):\n",
    "    results = nav_net_information_gain(session_data, constants, boot_params, time_diff, res=results)\n",
    "    results_ratio[time_diff] = np.divide(net_information_gain_cue, results[time_diff][0], out=np.zeros_like(net_information_gain_cue), where=results[time_diff][0]!=0)\n",
    "    average_ratio += results_ratio[time_diff]\n",
    "\n",
    "average_ratio /= num_cells\n",
    "average_ratio = average_ratio.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change results from a dictionary to an array\n",
    "results_arr = np.zeros((len(results), num_cells))\n",
    "results_err_arr = np.zeros((len(results), num_cells, 2))\n",
    "for time_diff, res in results.items():\n",
    "    results_arr[time_diff,:] = res[0]\n",
    "    results_err_arr[time_diff,:,0] = res[1][0]\n",
    "    results_err_arr[time_diff,:,1] = res[1][1]\n",
    "results_arr = results_arr.T\n",
    "results_err_arr = np.swapaxes(results_err_arr, 0, 1)\n",
    "\n",
    "# Change results_ratio from a dictionary to an array\n",
    "results_ratio_arr = np.zeros((len(results_ratio), num_cells))\n",
    "for time_diff, res in results_ratio.items():\n",
    "    results_ratio_arr[time_diff-1,:] = res\n",
    "results_ratio_arr = results_ratio_arr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "results_arr_scaled = np.empty_like(results_arr)\n",
    "for idx, row in enumerate(results_arr):\n",
    "    results_arr_scaled[idx,:] = minmax_scale(row)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f'Information gain (goal) across trial - {day_dir}')\n",
    "plt.pcolormesh(results_arr_scaled)\n",
    "plt.colorbar(label='Information gain (minmax scaled)')\n",
    "plt.axvline(x=1,color='k', linestyle='--')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.yticks(np.arange(0.5, num_cells+0.5), cell_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(f'Information gain (goal) across trial - {day_dir}')\n",
    "plt.pcolormesh(results_arr)\n",
    "plt.colorbar(label='Information gain')\n",
    "plt.axvline(x=1,color='k', linestyle='--')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.yticks(np.arange(0.5, num_cells+0.5), cell_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one cell to plot\n",
    "cell_num = 10\n",
    "cell_name = cell_labels[cell_num]\n",
    "\n",
    "# Extract timeseries for one cell\n",
    "cell_info = results_arr[cell_num,:]\n",
    "cell_info_err_lo = results_arr[cell_num,:] - results_err_arr[cell_num,:,0]\n",
    "cell_info_err_hi = results_err_arr[cell_num,:,1] - results_arr[cell_num,:]\n",
    "cell_info_err = (cell_info_err_lo, cell_info_err_hi)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f'Information gain (goal) across trial - {day_dir}, {cell_name}')\n",
    "plt.errorbar(np.arange(cell_info.shape[0]), cell_info, yerr=cell_info_err, fmt='-o', elinewidth=1, capsize=3)\n",
    "plt.axhline(y=cell_info[0], color='r', linestyle='--')\n",
    "plt.axvline(x=0.5, color='k', linewidth=1)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Information gain')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('decoding')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3fe2a2c8d7eb9520fbb1c58f5c7303a51cf224a80a092f134560e88ca87af0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
