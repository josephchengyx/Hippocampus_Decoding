{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import h5py\n",
    "from preproc import *\n",
    "from priordist import PriorDistributionCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which day's dataset to use\n",
    "prefix = \"/Volumes/Hippocampus/Data/picasso-misc/\"\n",
    "day_dir = \"20181102\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of cells under the day directory\n",
    "os.system(f\"sh ~/Documents/neural_decoding/Hippocampus_Decoding/get_cells.sh {day_dir}\")\n",
    "cell_list = list()\n",
    "with open(\"cell_list.txt\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        cell_list.append(line.strip())\n",
    "os.system(\"rm cell_list.txt\")\n",
    "\n",
    "# Load data from rplparallel.mat object, extract trial markers, time stamps and session start timestamp\n",
    "rp = h5py.File(prefix + day_dir + \"/session01/rplparallel.mat\")\n",
    "rp = rp.get('rp').get('data')\n",
    "trial_markers = np.array(rp.get('markers'))\n",
    "cue_intervals = np.array(rp.get('timeStamps'))\n",
    "session_start_time = np.round(np.array(rp.get('session_start_sec'))[0,0], 3)\n",
    "\n",
    "# Load data and extract spike times from all spiketrain.mat objects\n",
    "spike_times = list()\n",
    "cell_labels = list()\n",
    "for cell_dir in cell_list:\n",
    "    spk = loadmat(prefix + day_dir + \"/session01/\" + cell_dir + \"/spiketrain.mat\")\n",
    "    spk = spk.get('timestamps').flatten() # spike timestamps is loaded in as a column vector\n",
    "    spk = spk / 1000 # convert spike timestamps from msec to sec\n",
    "    spike_times.append(spk)\n",
    "    \n",
    "    cell_name = cell_dir.split('/')\n",
    "    array, channel, cell = cell_name[0][6:], cell_name[1][7:], cell_name[2][5:]\n",
    "    if channel[0] == '0':\n",
    "        channel = channel[1:]\n",
    "    cell_labels.append(f'a{array}/ch{channel}/c{cell}')\n",
    "\n",
    "# Load data from vmpv.mat object, extract session end timestamp\n",
    "pv = h5py.File(prefix + day_dir + \"/session01/1vmpv.mat\")\n",
    "pv = pv.get('pv').get('data')\n",
    "session_end_time = np.round(np.array(pv.get('rplmaxtime'))[0,0], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "250 ms time bins, 1 s binning statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get poster numbers from trial markers, cue phase time intervals\n",
    "trial_markers = trial_markers[0,:] % 10\n",
    "trial_markers = trial_markers.astype(int)\n",
    "cue_intervals = cue_intervals[0:2,:].T\n",
    "\n",
    "# Generate time intervals for each trial\n",
    "trial_intervals = np.empty_like(cue_intervals)\n",
    "trial_intervals[:,0] = cue_intervals[:,0]\n",
    "trial_intervals[:-1,1] = cue_intervals[1:,0]\n",
    "trial_intervals[-1,1] = session_end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin entire session into 1s time bins, aligned to the start of each cue phase for each trial\n",
    "session_intervals = list()\n",
    "delta = 1  # Size of time bin (in seconds)\n",
    "for idx, intvl in enumerate(trial_intervals):\n",
    "    trial_start, trial_end = intvl\n",
    "    for time in np.arange(trial_start, trial_end - delta, delta):\n",
    "        session_intervals.append(np.array([time, time + delta]))\n",
    "session_intervals = np.array(session_intervals)\n",
    "\n",
    "# Divide cue phases into 250 ms time bins\n",
    "new_cue_intervals = np.empty((cue_intervals.shape[0], cue_intervals.shape[1], 4))\n",
    "delta = 0.25  # Size of time bin (in seconds)\n",
    "for num, intvl in enumerate(cue_intervals):\n",
    "    st_time, ed_time = intvl\n",
    "    for prd in range(int(1/delta)):\n",
    "        new_cue_intervals[num,0,prd] = st_time + delta * prd\n",
    "        new_cue_intervals[num,1,prd] = st_time + delta * (prd + 1)\n",
    "cue_intervals = new_cue_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of cells in dataset\n",
    "num_cells = len(cell_labels)\n",
    "\n",
    "# Slot spikes into cue phase intervals for each trial\n",
    "spikecounts_per_trial = np.empty((cue_intervals.shape[0], num_cells, cue_intervals.shape[2]))\n",
    "for prd in range(cue_intervals.shape[2]):\n",
    "    spikecounts_per_trial[:,:,prd] = spike_counts_per_observation(cue_intervals[:,:,prd], spike_times)\n",
    "spikecounts_per_trial *= 4\n",
    "\n",
    "# Slot spikes into session time intervals\n",
    "spikecounts_across_session = spike_counts_per_observation(session_intervals, spike_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "spikecounts_cue_phase = np.sum(spikecounts_per_trial, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin spike counts within each cell for entire sesion, and get firing rate thresholds used for binning\n",
    "binned_spikes_across_session = np.empty_like(spikecounts_across_session)\n",
    "binning_stats = list()\n",
    "for col in range(spikecounts_across_session.shape[1]):\n",
    "    binned_spikes_across_session[:,col] = bin_firing_rates_4(spikecounts_across_session[:,col])\n",
    "    binning_stats.append(get_binning_stats_4(spikecounts_across_session[:,col]))\n",
    "\n",
    "# Bin spike counts within each cell for cue phases\n",
    "binned_spikes_per_trial = np.empty_like(spikecounts_per_trial)\n",
    "for prd in range(spikecounts_per_trial.shape[2]):\n",
    "    for col in range(spikecounts_per_trial.shape[1]):\n",
    "        binned_spikes_per_trial[:,col,prd] = bin_firing_rates_4(spikecounts_per_trial[:,col,prd], stats=binning_stats[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_goal(timeseries: np.array, goals: np.array) -> list:\n",
    "    num_goals = 6\n",
    "    grouped = [np.empty((0, timeseries.shape[1])) for _ in range(num_goals)]\n",
    "    for idx, goal in enumerate(goals):\n",
    "        goal = int(goal - 1)\n",
    "        grouped[goal] = np.vstack((grouped[goal], timeseries[idx,:]))\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group cue phase spikes according to goal\n",
    "responses_per_goal = list()\n",
    "for prd in range(binned_spikes_per_trial.shape[2]):\n",
    "    responses_per_goal.append(group_by_goal(binned_spikes_per_trial[:,:,prd], trial_markers))\n",
    "\n",
    "# Get distribution of population responses across entire session\n",
    "response_distribution_session = list()\n",
    "for responses in responses_per_goal:\n",
    "    response_distribution_session.append(PriorDistributionCell(binned_spikes_across_session, responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some important constants\n",
    "num_goals = 6\n",
    "num_cats = 4\n",
    "num_prds = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shannon entropy across goals\n",
    "goal_entropy = 0\n",
    "for goal in range(num_goals):\n",
    "    P_s = response_distribution_session[0].P_s(goal)\n",
    "    goal_entropy -= P_s * np.log2(P_s)\n",
    "\n",
    "print(goal_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log2(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unconditioned entropy of responses across entire session\n",
    "session_entropy = np.zeros(num_cells)\n",
    "for cell in range(num_cells):\n",
    "    for cat in range(num_cats):\n",
    "        P_r = response_distribution_session[0].P_r(cell, cat)\n",
    "        if P_r != 0:\n",
    "            session_entropy[cell] -= P_r * np.log2(P_r)\n",
    "\n",
    "print(session_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditioned entropy of responses per goal\n",
    "goal_response_entropy = np.zeros((num_goals, num_cells, num_prds))\n",
    "for prd in range(num_prds):\n",
    "    for goal in range(num_goals):\n",
    "        for cell in range(num_cells):\n",
    "            for cat in range(num_cats):\n",
    "                P_r_s = response_distribution_session[prd].P_r_s(cell, cat, goal)\n",
    "                if P_r_s != 0:\n",
    "                    goal_response_entropy[goal, cell, prd] -= P_r_s * np.log2(P_r_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information gain per stimulus (relative to entire session responses)\n",
    "information_gain = np.zeros((num_goals, num_cells, num_prds))\n",
    "for prd in range(num_prds):\n",
    "    for goal in range(num_goals):\n",
    "        for cell in range(num_cells):\n",
    "            for cat in range(num_cats):\n",
    "                P_r_s = response_distribution_session[prd].P_r_s(cell, cat, goal)\n",
    "                P_r = response_distribution_session[prd].P_r(cell, cat)\n",
    "                if P_r_s != 0:\n",
    "                    information_gain[goal, cell, prd] += P_r_s * np.log2(P_r_s / P_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Net information gain acrosss entire stimuli set\n",
    "net_information_gain = np.zeros((num_cells, num_prds))\n",
    "for prd in range(num_prds):\n",
    "    for cell in range(num_cells):\n",
    "        for goal in range(num_goals):\n",
    "            I_s_R = information_gain[goal, cell, prd]\n",
    "            P_s = response_distribution_session[prd].P_s(goal)\n",
    "            net_information_gain[cell, prd] += P_s * I_s_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scale_values(arr: np.array) -> np.array:\n",
    "    res = np.empty_like(arr)\n",
    "    tot = np.sum(arr)\n",
    "    if tot == 0:\n",
    "        tot = 1\n",
    "    for i, val in enumerate(arr):\n",
    "        res[i] = val / tot\n",
    "    return res\n",
    "\n",
    "net_info_gain = np.empty_like(net_information_gain)\n",
    "for idx, row in enumerate(net_information_gain):\n",
    "    net_info_gain[idx,:] = scale_values(row)\n",
    "\n",
    "plt.figure()\n",
    "plt.pcolormesh(net_info_gain)\n",
    "plt.title(f'Ratio of information gain across cue phase - {day_dir}')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.xticks(np.arange(0, int(1/delta)+1), [delta * i for i in range(0, int(1/delta)+1)])\n",
    "plt.yticks(np.arange(num_cells), cell_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.pcolormesh(net_information_gain)\n",
    "plt.colorbar()\n",
    "plt.title(f'Information gain across cue phase - {day_dir}')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.xticks(np.arange(0, int(1/delta)+1), [delta * i for i in range(0, int(1/delta)+1)])\n",
    "plt.yticks(np.arange(num_cells), cell_labels)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('decoding')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3fe2a2c8d7eb9520fbb1c58f5c7303a51cf224a80a092f134560e88ca87af0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
